---
title: MFU
mathjax: true
toc: true
date: 2026-01-25 17:08:11
updated: 2026-01-25 17:08:11
categories:
- Machine Learning
tags:
- MFU
---


**MFU（Model FLOPs Utilization，模型浮点运算利用率）** 是衡量深度神经网络（DNN）在训练或推理过程中**硬件计算效率**的关键指标。它回答了一个核心问题：

> **“我们的 GPU/TPU 算力，到底有多少真正用在了模型计算上？”**

<!--more-->

___
## 1. MFU 的定义

MFU 表示模型在实际运行中**有效利用的浮点运算比例**，相对于硬件理论上能够提供的最大浮点运算能力（FLOPS）：

$$
\text{MFU} = \frac{\text{实际执行的有效 FLOPs/s}}{\text{硬件理论峰值 FLOPs/s}}
$$

- **分子（有效 FLOPs/s）**：  
  模型一次前向（或前向+反向）传播所需的浮点运算量（由模型结构精确计算），除以实际耗时。
  
- **分母（峰值 FLOPS）**：  
  所用硬件在理想情况下的最大计算吞吐（例如 NVIDIA A100 在 FP16 下约为 $3.12 \times 10^{14}$ FLOPS）。

✅ **MFU 越高，说明硬件资源越高效地用于“有意义的计算”**，而非浪费在通信、内存瓶颈或调度开销上。

> 💡 **注意**：本文以**前向传播**为例计算 MFU，这是评估推理或训练吞吐时的常见简化场景。

---

## 2. 实例演示：三层 MLP 的 MFU 计算

考虑一个简单的 3 层全连接网络（MLP）：

- **层 1**：$1024 \rightarrow 4096$  
- **层 2**：$4096 \rightarrow 4096$  
- **层 3**：$4096 \rightarrow 1024$  
- **批量大小（Batch Size）**：$B = 64$  
- **硬件**：NVIDIA A100（FP16 峰值算力 = $3.12 \times 10^{14}$ FLOPS）

#### 2.1 计算前向传播 FLOPs

单层 MLP 前向传播的 FLOPs 公式为：
$$
\text{FLOPs}_{\text{layer}} = 2 \times B \times d_{\text{in}} \times d_{\text{out}}
$$
> 注：乘加操作（multiply-add）计为 2 次浮点运算。

逐层计算：

| 层 | 计算式 | FLOPs |
|----|--------|--------|
| 层 1 | $2 \times 64 \times 1024 \times 4096$ | 536,870,912 |
| 层 2 | $2 \times 64 \times 4096 \times 4096$ | 2,147,483,648 |
| 层 3 | $2 \times 64 \times 4096 \times 1024$ | 536,870,912 |

**总 FLOPs**：
$$
536.87\,\text{M} + 2,147.48\,\text{M} + 536.87\,\text{M} = 3,221.22\,\text{M} = 3.221 \times 10^9\ \text{FLOPs}
$$

#### 2.2 计算 MFU

假设该前向传播在 A100 上耗时极短（理想情况下仅受算力限制），则理论最大 FLOPs/s 为 $3.12 \times 10^{14}$。

但即使我们**瞬时完成**这次前向（即耗时趋近于 0），MFU 仍由单位时间内的有效算力决定。若以“单次前向”为单位，则：

$$
\text{MFU} = \frac{3.221 \times 10^9}{3.12 \times 10^{14}} \approx 0.001\%
$$

> 🔥 **结论**：这个小模型的 MFU 极低！  
> 原因：A100 的算力极其强大（312 TFLOPS），而小型 MLP 的计算量太小，无法“喂饱”GPU。

✅ **启示**：要提升 MFU，必须使用**更大模型**或**更大 batch size**，以提高计算密度。

___
## 3. 如何提高 MFU？

以下策略可显著提升 MFU，尤其在大模型训练中至关重要：

| 优化方向 | 具体方法 |
|--------|--------|
| **增大 Batch Size** | 提高计算密度，摊薄通信与 kernel 启动开销 |
| **高效并行策略** | 结合 Tensor Parallelism、Pipeline Parallelism、ZeRO 等 |
| **Kernel 优化** | 使用 fused kernels、FlashAttention、cuBLASLt 等 |
| **减少通信瓶颈** | 利用 NVLink/InfiniBand，重叠计算与通信（如梯度同步） |
| **混合精度训练** | 使用 FP16/BF16，既节省显存又提升 FLOPS 利用率 |

> 📌 **行业参考值**：  
> - LLaMA 训练 MFU：30%–40%  
> - PaLM 训练 MFU：约 46%  
> - 高度优化系统：可达 50%+（但极少超过 60%）

___
## 4. MFU vs GPU 利用率：本质区别

很多人误将 `nvidia-smi` 中的 **GPU-Util%** 当作性能指标，但它与 MFU **完全不同**，甚至可能产生误导。

#### 4.1 核心对比

| 维度 | **MFU** | **GPU 利用率（GPU-Util%）** |
|------|--------|---------------------------|
| **衡量对象** | 模型计算效率（有效 FLOPs / 峰值 FLOPs） | GPU 是否“有事做”（任意引擎活跃时间占比） |
| **关注点** | **有意义的浮点运算**是否被充分利用 | GPU 的任一单元（SM、Copy Engine、解码器等）是否忙碌 |
| **是否反映模型效率** | ✅ 是 | ❌ 否（可能“忙但无效”） |
| **受通信/IO 影响** | ✅ 是（通信不产生 FLOPs） | ❌ 否（拷贝数据也会拉高利用率） |

#### 4.2 为什么 GPU-Util% 很“虚”？

`nvidia-smi` 的 GPU-Util% 定义为：  
> “在过去采样周期内，GPU 上**至少有一个引擎处于活跃状态**的时间比例。”

这意味着：

- 即使 GPU 只在做 **CPU→GPU 数据拷贝**（无任何矩阵运算），Util% 也可能显示 **90%+**。
- 小 batch 导致频繁 kernel 启动和空闲，Util% 仍可能“看起来不错”。

#### 📌 场景举例

> **情况**：训练大模型，batch size 太小，每次前向仅 1ms，随后等待 9ms 进行 All-Reduce 同步。  
> - **GPU-Util%**：≈60%（采样捕捉到计算片段）  
> - **MFU**：<10%（90% 时间未执行有效 FLOPs）

> **情况**：内存带宽受限的 wide MLP  
> - **GPU-Util%**：80%（memory controller 忙）  
> - **MFU**：15%（SM 单元“饿死”，无法满负荷计算）

#### 4.3 一个形象比喻

- **GPU 利用率** ≈ “工厂的灯是不是亮着”  
  → 灯亮 ≠ 在生产，可能只是有人在擦地板。

- **MFU** ≈ “生产线每小时产出 / 理论最大产能”  
  → 直接衡量**有效产出效率**。

---

## 5. 总结

> ✅ **MFU 是衡量“算力是否被有效用于模型计算”的黄金指标**。  
> ✅ 高 MFU = 高训练效率 = 低成本。  
> ✅ 在千亿参数模型时代，**提升几个百分点的 MFU，可能节省数百万美元训练费用**。

> ❌ 不要被 `nvidia-smi` 的 GPU-Util% 迷惑——它告诉你 GPU “在忙”，但没说“忙得值不值”。