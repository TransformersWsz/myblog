---
title: 多标签分类新建模方法
mathjax: true
toc: true
date: 2024-03-18 02:05:24
updated: 2024-03-18 02:05:24
categories:
- CV
tags:
- Multi-label Classification
- Transformer
---
常见的多标签分类方法是同时生成多个标签的logits，然后接一个sigmoid激活函数做二分类。该方法简单直接，但忽略了标签之间的相关性。虽然业界针对该问题提出了很多解决思路，但大多是任务特定，通用性不强，也不够优雅。

<!--more-->

Transformer decoder倒是可以序列输出多个标签，但却加入了位置偏差。而标签之间是没有位置关系的，谁先谁后无所谓，只要输出全就行。这样也导致数据集不好构造。


## C-Tran

[General Multi-label Image Classification with Transformers](https://openaccess.thecvf.com/content/CVPR2021/papers/Lanchantin_General_Multi-Label_Image_Classification_With_Transformers_CVPR_2021_paper.pdf) 这篇论文提供了新思路，类似BERT的MLM预训练任务：通过在输入端对多个标签做随机mask，然后预测被mask的标签，从而强制模型去学习标签之间的依赖关系：

![model](https://raw.githubusercontent.com/TransformersWsz/picx-images-hosting/master/image.92pw1se1sg.png)

模型细节：
![detail](https://raw.githubusercontent.com/TransformersWsz/picx-images-hosting/master/image.b8nozrlq2.webp)

![params](https://raw.githubusercontent.com/TransformersWsz/picx-images-hosting/master/image.7p3cxrf3jv.webp)

- Label Embeddings: 可学习的参数矩阵，由模型隐式学习到标签的语义信息和标签间依赖。有点像DETR的query
- State Embeddings: 控制标签的mask比例，这样就跟标签学习实现了解耦，也方便在推理阶段注入全比例mask

#### 实验结果
不说了，全是sota：

![exp](https://raw.githubusercontent.com/TransformersWsz/picx-images-hosting/master/image.92pw1sv1ar.webp)

___

- 旷视用gcn来建模多标签方法(被C-Tran超越了，建模思路可以学习)：[Multi-Label Image Recognition with Graph Convolutional Networks](https://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Multi-Label_Image_Recognition_With_Graph_Convolutional_Networks_CVPR_2019_paper.pdf)
